{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da9b3c20",
   "metadata": {},
   "source": [
    "# Mini Project 2 - Part 2\n",
    "\n",
    "#### Andrew Geday - 260834063\n",
    "#### Wassim Wazzi - 260825559\n",
    "#### Cesar Arnouk - 260847683"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d73cb0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f8b7aa",
   "metadata": {},
   "source": [
    "We append the validation set to the training set to have more data to train on, since no CV is implemented here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "12401ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get training data\n",
    "X = pd.read_csv(\"data_A2/fake_news/fake_news_train.csv\", sep=\",\") # training data\n",
    "X_val = pd.read_csv(\"data_A2/fake_news/fake_news_val.csv\", sep=\",\") # validation data\n",
    "X = X.append(X_val, ignore_index=True)\n",
    "\n",
    "Y_train = X.loc[:, 'label'].to_numpy() # array to label string\n",
    "X_train = X.iloc[:, 0:-1] # drop label in dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "47c2a3f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Indian fruit is so important to so many people...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FORT WORTH, Texas — Urú Inc. will hold a confe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>With three of the four new carriers, the Niger...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Let's start with the classic annual dividend r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Following are some of the major events to have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21995</th>\n",
       "      <td>KABUL - In past several weeks, hectic negotiat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21996</th>\n",
       "      <td>1) Where is Wan-Bissaka in the young player sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21997</th>\n",
       "      <td>It may seem counterintuitive that Calgary shou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21998</th>\n",
       "      <td>The CEOs of America's biggest banks were summo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21999</th>\n",
       "      <td>A tenth-grader was crushed at a school by a 7-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text\n",
       "0      Indian fruit is so important to so many people...\n",
       "1      FORT WORTH, Texas — Urú Inc. will hold a confe...\n",
       "2      With three of the four new carriers, the Niger...\n",
       "3      Let's start with the classic annual dividend r...\n",
       "4      Following are some of the major events to have...\n",
       "...                                                  ...\n",
       "21995  KABUL - In past several weeks, hectic negotiat...\n",
       "21996  1) Where is Wan-Bissaka in the young player sh...\n",
       "21997  It may seem counterintuitive that Calgary shou...\n",
       "21998  The CEOs of America's biggest banks were summo...\n",
       "21999  A tenth-grader was crushed at a school by a 7-...\n",
       "\n",
       "[22000 rows x 1 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77fc9751",
   "metadata": {},
   "source": [
    "As in the provided tutorial, let's map raw text to features. The way we will do so is by creating a feature for every word that occurs in alln our dataset, and the feature's value will be the word's frequency:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3aaecf57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<22000x152673 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 5664886 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(X_train.text)\n",
    "X_train_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caaebf5d",
   "metadata": {},
   "source": [
    "For example, if we fetch the number of times the word 'indian' occured:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fc95d9ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68551"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vect.vocabulary_.get(u'indian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "06bca12c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22000, 152673)\n",
      "(22000, 152673)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tf_transformer = TfidfTransformer(use_idf=False).fit(X_train_counts)\n",
    "X_train_tf = tf_transformer.transform(X_train_counts)\n",
    "print(X_train_tf.shape)\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "print(X_train_tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9e32328f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert Numpy sparse matrix to Pandas DataFrame\n",
    "import scipy.sparse\n",
    "X_train_tfidf = pd.DataFrame.sparse.from_spmatrix(X_train_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9947f9d7",
   "metadata": {},
   "source": [
    "We are now done with mapping the text to featueres. Let's observe what our design matrix looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c69aa3e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>152663</th>\n",
       "      <th>152664</th>\n",
       "      <th>152665</th>\n",
       "      <th>152666</th>\n",
       "      <th>152667</th>\n",
       "      <th>152668</th>\n",
       "      <th>152669</th>\n",
       "      <th>152670</th>\n",
       "      <th>152671</th>\n",
       "      <th>152672</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.180029</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21995</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005808</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21996</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21997</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21998</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21999</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22000 rows × 152673 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1       2       3       4       5       6       7       \\\n",
       "0      0.000000  0.000000     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "1      0.180029  0.000000     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "2      0.000000  0.000000     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "3      0.000000  0.000000     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "4      0.000000  0.000000     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "...         ...       ...     ...     ...     ...     ...     ...     ...   \n",
       "21995  0.000000  0.005808     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "21996  0.000000  0.000000     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "21997  0.000000  0.000000     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "21998  0.000000  0.000000     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "21999  0.000000  0.000000     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "       8       9       ...  152663  152664  152665  152666  152667  152668  \\\n",
       "0         0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "1         0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "2         0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "3         0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "4         0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "...       ...     ...  ...     ...     ...     ...     ...     ...     ...   \n",
       "21995     0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "21996     0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "21997     0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "21998     0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "21999     0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "       152669  152670  152671  152672  \n",
       "0         0.0     0.0     0.0     0.0  \n",
       "1         0.0     0.0     0.0     0.0  \n",
       "2         0.0     0.0     0.0     0.0  \n",
       "3         0.0     0.0     0.0     0.0  \n",
       "4         0.0     0.0     0.0     0.0  \n",
       "...       ...     ...     ...     ...  \n",
       "21995     0.0     0.0     0.0     0.0  \n",
       "21996     0.0     0.0     0.0     0.0  \n",
       "21997     0.0     0.0     0.0     0.0  \n",
       "21998     0.0     0.0     0.0     0.0  \n",
       "21999     0.0     0.0     0.0     0.0  \n",
       "\n",
       "[22000 rows x 152673 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4622eea0",
   "metadata": {},
   "source": [
    "We now run logistic regression on our data using scikit-learn tools:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "dc1cb443",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# instantiate the model (using the default parameters)\n",
    "logreg = LogisticRegression(random_state=0)\n",
    "\n",
    "# fit the model with data\n",
    "logreg.fit(X_train_tfidf, Y_train)\n",
    "\n",
    "#get training data\n",
    "X_t = pd.read_csv(\"data_A2/fake_news/fake_news_test.csv\", sep=\",\") # test data\n",
    "Y_test = X_t.loc[:, 'label'].to_numpy() # array to label string\n",
    "X_test = X_t.iloc[:, 0:-1] # drop label from dataframe\n",
    "\n",
    "# feature extracting chain\n",
    "X_test_counts = count_vect.transform(X_test.text)\n",
    "X_test_tfidf = tfidf_transformer.transform(X_test_counts)\n",
    "\n",
    "# predict on new data\n",
    "Yh = logreg.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9a69c78d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.716"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(Yh == Y_test)/len(Yh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b818cd4d",
   "metadata": {},
   "source": [
    "This was just the basic version of what was asked of us. We get an accuracy of 0.716 for this model.\n",
    "<br>\n",
    "Now, let's try to go above and beyond."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9508d84",
   "metadata": {},
   "source": [
    "### Above and beyond"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b96a13b",
   "metadata": {},
   "source": [
    "Apart from count vectors and tf-idf, we try to clean our data as much as possible to avoid noise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "471d510d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(\n",
    "    string: str, \n",
    "    punctuations=r'''!()-[]{};:'\"\\,<>./?@#$%^&*_~''',\n",
    "    stop_words=['the', 'a', 'and', 'is', 'be', 'will']) -> str:\n",
    "    \"\"\"\n",
    "    A method to clean text \n",
    "    \"\"\"\n",
    "    # Cleaning the urls\n",
    "    string = re.sub(r'https?://\\S+|www\\.\\S+', '', string)\n",
    "\n",
    "    # Cleaning the html elements\n",
    "    string = re.sub(r'<.*?>', '', string)\n",
    "\n",
    "    # Removing the punctuations\n",
    "    for x in string.lower(): \n",
    "        if x in punctuations: \n",
    "            string = string.replace(x, \"\") \n",
    "\n",
    "    # Converting the text to lower\n",
    "    string = string.lower()\n",
    "\n",
    "    # Removing stop words\n",
    "#     string = ' '.join([word for word in string.split() if word not in stop_words])\n",
    "\n",
    "    # Cleaning the whitespaces\n",
    "    string = re.sub(r'\\s+', ' ', string).strip()\n",
    "\n",
    "    return string\n",
    "\n",
    "# clean the text in our dataframe\n",
    "for i in range(0,X_train.shape[0]):\n",
    "    X_train.iloc[i]['text'] = clean_text(X_train.iloc[i]['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38775b9a",
   "metadata": {},
   "source": [
    "Now we preprocess as we did before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "fc82a03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import scipy.sparse\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(X_train.text)\n",
    "\n",
    "tf_transformer = TfidfTransformer(use_idf=False).fit(X_train_counts)\n",
    "X_train_tf = tf_transformer.transform(X_train_counts)\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "\n",
    "# convert Numpy sparse matrix to Pandas DataFrame\n",
    "X_train_tfidf = pd.DataFrame.sparse.from_spmatrix(X_train_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef464b2",
   "metadata": {},
   "source": [
    "We predict as we did on the newly processed data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "8771524a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the model (using the default parameters)\n",
    "logreg = LogisticRegression(random_state=0)\n",
    "\n",
    "# fit the model with data\n",
    "logreg.fit(X_train_tfidf, Y_train)\n",
    "\n",
    "#get training data\n",
    "X_t = pd.read_csv(\"data_A2/fake_news/fake_news_test.csv\", sep=\",\") # test data\n",
    "Y_test = X_t.loc[:, 'label'].to_numpy() # array to label string\n",
    "X_test = X_t.iloc[:, 0:-1] # drop label from dataframe\n",
    "\n",
    "# feature extracting chain\n",
    "X_test_counts = count_vect.transform(X_test.text)\n",
    "X_test_tfidf = tfidf_transformer.transform(X_test_counts)\n",
    "\n",
    "# predict on new data\n",
    "Yh = logreg.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ef5e9ac8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7043333333333334"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(Yh == Y_test)/len(Yh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b33036",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "971f6570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now trying out 5-fold cross-validation\n",
      "Now trying out 10-fold cross-validation\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "cv_values = [5,10]\n",
    "accuracies = {}\n",
    "\n",
    "for cv in cv_values:\n",
    "    print('Now trying out ' + str(cv) + '-fold cross-validation')\n",
    "    # instantiate the model (using the default parameters)\n",
    "    logregCV = LogisticRegressionCV(cv=cv, random_state=0)\n",
    "\n",
    "    # fit the model with data\n",
    "    logregCV.fit(X_train_tfidf, Y_train)\n",
    "\n",
    "    #get training data\n",
    "    X_t = pd.read_csv(\"data_A2/fake_news/fake_news_test.csv\", sep=\",\") # test data\n",
    "    Y_test = X_t.loc[:, 'label'].to_numpy() # array to label string\n",
    "    X_test = X_t.iloc[:, 0:-1] # drop label from dataframe\n",
    "\n",
    "    # feature extracting chain\n",
    "    X_test_counts = count_vect.transform(X_test.text)\n",
    "    X_test_tfidf = tfidf_transformer.transform(X_test_counts)\n",
    "\n",
    "    # predict on new data\n",
    "    Yh = logregCV.predict(X_test_tfidf)\n",
    "    \n",
    "    accuracies[cv] = sum(Yh == Y_test)/len(Yh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "50032de9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{5: 0.7216666666666667, 10: 0.7216666666666667}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
